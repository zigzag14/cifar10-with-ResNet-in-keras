{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the ResNet with Keras\n",
    "## notes:\n",
    "1. The model is trained on Kaggle with a NVIDIA Tesla K80. It typically takes a few hours (200 epochs, batch size= 128) to train the model. The trained model is save in .h5 format. Open test_script.ipynb to play with the trained models.\n",
    "2. L2 regularization improves the accuracy by 0.5% ~ 1% \n",
    "3. Although it is sometimes claimed ResNet with bottleneck layer is better than the regular ResNet. ResNet with bottleneck layer is actually slightly worse than the regular ResNet in my case. Nevertheless, adding ResNet with bottleneck layer to the ensembled model helps the final results as expected. \n",
    "4. contact info: fengjc1214@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "import os\n",
    "from keras import regularizers\n",
    "import utilities\n",
    "import read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##parameter list\n",
    "# download cifar 10 at: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "img_path = './cifar-10-batches-py/'    #the file path of the training & testing data\n",
    "batch_size = 128  \n",
    "epochs = 200\n",
    "regu= 0.0003             ## regularization weight\n",
    "num_layer= 30            ## number of layers in ResNet, it should satisfy num_layer= 6*n +2 where n is an integer\n",
    "                         ## if not, num_layer will be converted to a number satisfying 6*n+2 \n",
    "n= int((num_layer-2)/6)\n",
    "print('The input num_layer is: '+ str(num_layer)+', The actual num_layer is: '+ str(6*n+2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, filters, f=3):\n",
    "    \"\"\" identity block    H and W is unchaged before and after identity block\n",
    "    Inputs:\n",
    "    X -- input tensor (m, H_prev, W_prev, C_prev)\n",
    "    filters -- the number of filters\n",
    "    f -- filter size is (f, f)\n",
    "    \n",
    "    Output:\n",
    "    X -- output tensor (H, W, C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save the input value for later\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First layer of main path\n",
    "    X = Conv2D(filters = filters, kernel_size = (f, f), strides = (1,1),kernel_regularizer=regularizers.l2(regu), padding = 'same', kernel_initializer = glorot_uniform())(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second layer of main path\n",
    "    X = Conv2D(filters = filters, kernel_size = (f, f), strides = (1,1), kernel_regularizer=regularizers.l2(regu), padding = 'same', kernel_initializer = glorot_uniform())(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "\n",
    "    # Add shortcut value to main path\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, filters, f = 3, s= 2):\n",
    "    \"\"\"\n",
    "    convolutional block    H and W shrink by half due to stride =2 after the convolutional block\n",
    "    \n",
    "    H=H_prev/2, W=W_prev/2 with stride=2\n",
    "    \n",
    "    Inputs:\n",
    "    X -- input tensor (m, H_prev, W_prev, C_prev)\n",
    "    filters -- the number of filters\n",
    "    f -- filter size is (f, f)\n",
    "    s -- stride\n",
    "    Outputs:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save the input value for later\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First layer of main path \n",
    "    X = Conv2D(filters, (f, f), strides = (s,s), padding = 'same', kernel_regularizer=regularizers.l2(regu), kernel_initializer = glorot_uniform())(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second layer of main path \n",
    "    X = Conv2D(filters, (f, f), strides = (1,1), padding = 'same', kernel_regularizer=regularizers.l2(regu), kernel_initializer = glorot_uniform())(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "\n",
    "    # First layer of the shortcut path\n",
    "    X_shortcut = Conv2D(filters, (1, 1), strides = (s,s), padding = 'same', kernel_initializer = glorot_uniform())(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut)\n",
    "\n",
    "    # Add shortcut value to main path\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(input_shape = (32, 32, 3), classes = 10, n=3):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    input_shape -- shape of the images of the dataset (H=32, W=32, C=3)\n",
    "    classes -- number of classes\n",
    "    n -- number of blocks in each stage\n",
    "    \n",
    "    Outputs:\n",
    "    model -- a Model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct an input tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Padding\n",
    "    X = ZeroPadding2D((1, 1))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    \n",
    "    ## output size 32 by 32, 16 filters\n",
    "    \n",
    "    X = Conv2D(16, (3, 3), strides = (1, 1), name = 'conv1', kernel_regularizer=regularizers.l2(regu), kernel_initializer = glorot_uniform())(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Stage 2  output size 32 by 32, 16 filters\n",
    "    X = identity_block(X, filters = 16)\n",
    "    for i in range(n-1):\n",
    "        X = identity_block(X, filters = 16)\n",
    "\n",
    "    # Stage 3 output size 16 by 16, 32 filters \n",
    "    X = convolutional_block(X, filters = 32)\n",
    "    for i in range(n-1):\n",
    "        X = identity_block(X, filters = 32)\n",
    "    \n",
    "\n",
    "    # Stage 4 output size 8 by 8, 64 filters\n",
    "    X = convolutional_block(X, filters = 64)\n",
    "    for i in range(n-1):\n",
    "        X = identity_block(X, filters = 64)\n",
    "    \n",
    "    # Stage 5, averagepooling, output size (1, 1, 64)\n",
    "\n",
    "    X = AveragePooling2D(pool_size=(8, 8), strides=None, name=\"avg_pool\")(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_regularizer=regularizers.l2(regu), kernel_initializer = glorot_uniform())(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(input_shape = (32, 32, 3), classes = 10, n= n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=utilities.lr_decay(0)),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = read_file.img_read(img_path)  \n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        )\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "modelname=\"ResNet_l\"+str(num_layer)\n",
    "\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    epochs=epochs, verbose=1,\n",
    "                    callbacks=utilities.lr_callbacks(modelname))\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
